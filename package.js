{
  "name": "Crawling",
  "version": "1.0.0",
  "description": "Crawl blogging website https://medium.com and find all possible hyperlinks present within https://medium.com website and generate output.",
  "main": "index.js",
  "scripts": {
    "start": "node app.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "engines": {
    "node": ">=6.2.2 <7.0.0"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/anilchoudhary9/crawling"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "bugs": {
    "url": "https://github.com/anilchoudhary9/crawling/issues"
  },
  "homepage": "https://github.com/anilchoudhary9/crawling",
  "devDependencies": {
    "eslint": "3.1.1",
    "eslint-config-airbnb": "9.0.1",
    "eslint-plugin-import": "1.11.0",
    "jscs": "3.0.7"
  },
  "dependencies": {
    "bluebird": "3.4.1",
    "debug": "2.2.0",
    "lodash": "4.13.1",
    "scraperjs": "1.2.0"
  }
}
